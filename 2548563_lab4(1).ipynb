{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import libraries"
      ],
      "metadata": {
        "id": "rGgfiVTLyiww"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z9WiU1JpxVUf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import struct"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading IDX files"
      ],
      "metadata": {
        "id": "ZVyg0B0sywNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(path, limit):\n",
        "    with open(path, 'rb') as f:\n",
        "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
        "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "        images = images.reshape(num, rows, cols)\n",
        "        return images[:limit] / 255.0\n",
        "\n",
        "def load_labels(path, limit):\n",
        "    with open(path, 'rb') as f:\n",
        "        magic, num = struct.unpack(\">II\", f.read(8))\n",
        "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "        return labels[:limit]"
      ],
      "metadata": {
        "id": "HbLPlEWKxvFx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading the dataset"
      ],
      "metadata": {
        "id": "IPCesdYnylOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Data (500)\n",
        "X_train = load_images(\"train-images-idx3-ubyte\", 500)\n",
        "y_train = load_labels(\"train-labels-idx1-ubyte\", 500)\n",
        "\n",
        "# Load test data\n",
        "X_test = load_images(\"t10k-images-idx3-ubyte\", 100)\n",
        "y_test = load_labels(\"t10k-labels-idx1-ubyte\", 100)"
      ],
      "metadata": {
        "id": "HSNx1_aUyOat"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training shape:\", X_train.shape)\n",
        "print(\"Testing shape:\", X_test.shape)"
      ],
      "metadata": {
        "id": "7blC2cssgNYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b23e6e5b-afc0-4a0e-e61f-705a6fe09900"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training shape: (500, 28, 28)\n",
            "Testing shape: (100, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INITIALIZE PARAMETERS"
      ],
      "metadata": {
        "id": "lWFFj6wrfEdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_filters = 12\n",
        "filter_size = 3\n",
        "num_classes = 10\n",
        "learning_rate = 0.005\n",
        "\n",
        "filters = np.random.randn(num_filters, filter_size, filter_size) * 0.1\n",
        "fc_input_size = 13 * 13 * num_filters\n",
        "W_fc = np.random.randn(fc_input_size, num_classes) * 0.1\n",
        "b_fc = np.zeros(num_classes)"
      ],
      "metadata": {
        "id": "Q_9YH0bAfGtd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ACTIVATION & LOSS FUNCTIONS"
      ],
      "metadata": {
        "id": "IG6avPTKfLnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def softmax(x):\n",
        "    exp = np.exp(x - np.max(x))\n",
        "    return exp / np.sum(exp)\n",
        "\n",
        "def cross_entropy(pred, label):\n",
        "    return -np.log(pred[label] + 1e-9)"
      ],
      "metadata": {
        "id": "U8aSqZ-dfJNl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONVOLUTION"
      ],
      "metadata": {
        "id": "wPMSuJK0fQ2v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(image, filters):\n",
        "    h, w = image.shape\n",
        "    f = filters.shape[1]\n",
        "    output = np.zeros((num_filters, h-f+1, w-f+1))\n",
        "\n",
        "    for n in range(num_filters):\n",
        "        for i in range(h-f+1):\n",
        "            for j in range(w-f+1):\n",
        "                output[n, i, j] = np.sum(\n",
        "                    image[i:i+f, j:j+f] * filters[n]\n",
        "                )\n",
        "    return output"
      ],
      "metadata": {
        "id": "MP8iowQyfOsx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAX POOLING (2x2)"
      ],
      "metadata": {
        "id": "N82J0AidfWPc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maxpool(feature_map):\n",
        "    num_f, h, w = feature_map.shape\n",
        "    output = np.zeros((num_f, h//2, w//2))\n",
        "\n",
        "    for n in range(num_f):\n",
        "        for i in range(0, h, 2):\n",
        "            for j in range(0, w, 2):\n",
        "                output[n, i//2, j//2] = np.max(\n",
        "                    feature_map[n, i:i+2, j:j+2]\n",
        "                )\n",
        "    return output"
      ],
      "metadata": {
        "id": "qiXHEsVzfTxe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TRAINING"
      ],
      "metadata": {
        "id": "HUSkbcKwfa7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50):\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    for i in range(500):\n",
        "        image = X_train[i]\n",
        "        label = y_train[i]\n",
        "\n",
        "        # Forward pass\n",
        "        conv_out = conv(image, filters)\n",
        "        relu_out = relu(conv_out)\n",
        "        pool_out = maxpool(relu_out)\n",
        "\n",
        "        flat = pool_out.flatten()\n",
        "        logits = np.dot(flat, W_fc) + b_fc\n",
        "        probs = softmax(logits)\n",
        "\n",
        "        loss = cross_entropy(probs, label)\n",
        "        total_loss += loss\n",
        "\n",
        "        if np.argmax(probs) == label:\n",
        "            correct += 1\n",
        "\n",
        "        # Backprop (Fully connected layer only)\n",
        "        d_logits = probs\n",
        "        d_logits[label] -= 1\n",
        "\n",
        "        dW_fc = np.outer(flat, d_logits)\n",
        "        db_fc = d_logits\n",
        "\n",
        "        W_fc -= learning_rate * dW_fc\n",
        "        b_fc -= learning_rate * db_fc\n",
        "\n",
        "    print(\"Epoch:\", epoch+1,\n",
        "          \"Loss:\", total_loss/500,\n",
        "          \"Train Accuracy:\", correct/500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMEzZ4wrfYxu",
        "outputId": "55ce3834-5df3-4df2-f451-072385e57428"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 Loss: 0.4579734168700988 Train Accuracy: 0.876\n",
            "Epoch: 2 Loss: 0.44994552107852476 Train Accuracy: 0.884\n",
            "Epoch: 3 Loss: 0.44546752205735873 Train Accuracy: 0.89\n",
            "Epoch: 4 Loss: 0.44099529943144494 Train Accuracy: 0.89\n",
            "Epoch: 5 Loss: 0.4366769816291712 Train Accuracy: 0.89\n",
            "Epoch: 6 Loss: 0.43250469639462213 Train Accuracy: 0.89\n",
            "Epoch: 7 Loss: 0.4284602320583696 Train Accuracy: 0.892\n",
            "Epoch: 8 Loss: 0.42452934065631037 Train Accuracy: 0.894\n",
            "Epoch: 9 Loss: 0.42070130355676255 Train Accuracy: 0.894\n",
            "Epoch: 10 Loss: 0.4169678147046128 Train Accuracy: 0.894\n",
            "Epoch: 11 Loss: 0.41332221822209053 Train Accuracy: 0.896\n",
            "Epoch: 12 Loss: 0.40975902073356313 Train Accuracy: 0.896\n",
            "Epoch: 13 Loss: 0.4062735727808641 Train Accuracy: 0.896\n",
            "Epoch: 14 Loss: 0.4028618545136318 Train Accuracy: 0.898\n",
            "Epoch: 15 Loss: 0.3995203277425251 Train Accuracy: 0.902\n",
            "Epoch: 16 Loss: 0.39624583154541065 Train Accuracy: 0.902\n",
            "Epoch: 17 Loss: 0.3930355071823889 Train Accuracy: 0.902\n",
            "Epoch: 18 Loss: 0.3898867431297876 Train Accuracy: 0.902\n",
            "Epoch: 19 Loss: 0.3867971341490959 Train Accuracy: 0.904\n",
            "Epoch: 20 Loss: 0.38376445028214695 Train Accuracy: 0.904\n",
            "Epoch: 21 Loss: 0.3807866129546154 Train Accuracy: 0.906\n",
            "Epoch: 22 Loss: 0.3778616762310102 Train Accuracy: 0.908\n",
            "Epoch: 23 Loss: 0.37498781184789837 Train Accuracy: 0.91\n",
            "Epoch: 24 Loss: 0.3721632970525902 Train Accuracy: 0.91\n",
            "Epoch: 25 Loss: 0.3693865045520729 Train Accuracy: 0.912\n",
            "Epoch: 26 Loss: 0.3666558940710302 Train Accuracy: 0.912\n",
            "Epoch: 27 Loss: 0.3639700051544844 Train Accuracy: 0.912\n",
            "Epoch: 28 Loss: 0.3613274509475408 Train Accuracy: 0.912\n",
            "Epoch: 29 Loss: 0.35872691275402147 Train Accuracy: 0.912\n",
            "Epoch: 30 Loss: 0.3561671352255291 Train Accuracy: 0.912\n",
            "Epoch: 31 Loss: 0.35364692206858983 Train Accuracy: 0.912\n",
            "Epoch: 32 Loss: 0.35116513218377965 Train Accuracy: 0.912\n",
            "Epoch: 33 Loss: 0.34872067617007535 Train Accuracy: 0.912\n",
            "Epoch: 34 Loss: 0.3463125131419695 Train Accuracy: 0.912\n",
            "Epoch: 35 Loss: 0.3439396478175415 Train Accuracy: 0.912\n",
            "Epoch: 36 Loss: 0.3416011278437469 Train Accuracy: 0.912\n",
            "Epoch: 37 Loss: 0.3392960413312686 Train Accuracy: 0.912\n",
            "Epoch: 38 Loss: 0.33702351457600205 Train Accuracy: 0.912\n",
            "Epoch: 39 Loss: 0.3347827099478547 Train Accuracy: 0.916\n",
            "Epoch: 40 Loss: 0.332572823930446 Train Accuracy: 0.916\n",
            "Epoch: 41 Loss: 0.3303930852975351 Train Accuracy: 0.918\n",
            "Epoch: 42 Loss: 0.32824275341386155 Train Accuracy: 0.918\n",
            "Epoch: 43 Loss: 0.3261211166495628 Train Accuracy: 0.922\n",
            "Epoch: 44 Loss: 0.3240274908985696 Train Accuracy: 0.924\n",
            "Epoch: 45 Loss: 0.3219612181924213 Train Accuracy: 0.924\n",
            "Epoch: 46 Loss: 0.319921665401785 Train Accuracy: 0.926\n",
            "Epoch: 47 Loss: 0.31790822301875055 Train Accuracy: 0.926\n",
            "Epoch: 48 Loss: 0.31592030401357574 Train Accuracy: 0.928\n",
            "Epoch: 49 Loss: 0.31395734276015236 Train Accuracy: 0.928\n",
            "Epoch: 50 Loss: 0.3120187940249377 Train Accuracy: 0.928\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "F0kNXEn0gknt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "\n",
        "for i in range(100):\n",
        "    image = X_test[i]\n",
        "    label = y_test[i]\n",
        "\n",
        "    conv_out = conv(image, filters)\n",
        "    relu_out = relu(conv_out)\n",
        "    pool_out = maxpool(relu_out)\n",
        "\n",
        "    flat = pool_out.flatten()\n",
        "    logits = np.dot(flat, W_fc) + b_fc\n",
        "    probs = softmax(logits)\n",
        "\n",
        "    if np.argmax(probs) == label:\n",
        "        correct += 1\n",
        "\n",
        "print(\"Test Accuracy:\", correct/100)"
      ],
      "metadata": {
        "id": "0yZemM0NfeDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88285199-336f-4f42-a465-d9d5a3f08437"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interpretation\n",
        "The loss decreased steadily across epochs, indicating that the model was learning effectively. Training accuracy improved from 27% to 70%, demonstrating that the CNN was successfully extracting meaningful features. The final test accuracy of 65% shows that the model generalizes reasonably well to unseen data.\n",
        "\n",
        "After tuning the learning rate, increasing the number of filters, and training for more epochs, the model achieved a test accuracy of 77%, showing improved feature extraction and better generalization"
      ],
      "metadata": {
        "id": "sn9IWH1RoM6G"
      }
    }
  ]
}